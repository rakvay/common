Dissalow run pods on some nodes can be reached by taint:
    kubectl taint node artem-kube-cluster-node-axbtu node-role.kubernetes.io/ingress=:NoSchedule     -      prohibit run pods on artem-kube-cluster-node-axbtu node
    
For ingress pods can runs on ingress nodes after taint we should add toleration parameter for ingress nodes:
  tolerations:
  - key: "node-role.kubernets.io/ingress"
    operator: "Exists"
    
and configure nodeSelector:
  nodeSelector:
    kubernetes.io/os: "linux"
    node-role.kubernetes.io/ingress: "true"
    
To avoid situation when all the ingress pods will run on the same node we should use podAntiAffinity parameter:
  affinity:  
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchExpressions:
            - key: app.kubernetes.io/name
              operator: In
              values:
              - ingress-nginx
            - key: app.kubernetes.io/instance
              operator: In
              values:
              - ingress-nginx
            - key: app.kubernetes.io/component
              operator: In
              values:
              - controller
          topologyKey: kubernetes.io/hostname
***********************************************************************************************************
    kube-apiserver - предоставляет API кубера

    etcd - распределенное key-value хранилище для всех данных кластера. Необязательно располагается внутри мастера, может стоять как отдельный кластер

    kube-scheduler - планирует размещение подов на узлах кластера

    kube-controller-manager - запускает контроллеры

    kubelet - сервис или агент, который контролирует запуск основных компонентов (контейнеров) кластер
***********************************************************************************************************
Deployments - контроллер, который управляет состоянием развертывания подов, которое описывается в манифесте, следит за удалением и созданием экземпляров подов. Управляет контроллерами ReplicaSet.

ReplicaSet - гарантирует, что определенное количество экземпляров подов всегда будет запущено в кластере.

StatefulSets - так же как и Deployments, управляет развертыванием и масштабированием набора подов, но сохраняет набор идентификаторов и состояние для каждого пода.

DaemonSet - гарантирует, что на каждом узле кластера будет присутствовать экземпляр пода.

Jobs - создает определенное количество подов и смотрит, пока они успешно не завершат работу. Если под завершился с ошибкой, повторяет создание, которое мы описали определенное количество раз. Если под успешно отработал, записывает это в свой журнал.

CronJob - запускает контроллеры Jobs по определенному расписанию.
***********************************************************************************************************
    Разные стратегии обновления приложения. Приложения постоянно обновляются. Чтобы это проходило незаметно для пользователя и бизнеса, а сами обновления не ломались в процессе, оркестраторы имеют для этого разные стратегии:

        Rolling — новая версия приложения выкатывается постепенно. Например, у нас есть 5 реплик приложения, которые постепенно заменяют исходное, пока, наконец, версия полностью не заменится на новую.

        Recreate — достаточно простая стратегия, когда мы просто убиваем старую версию и раскатываем новую.

        Blue/Green — мы выкатываем на стенды сразу 2 версии приложения: пока одна работает, вторая тестируется и со временем заменяет первую.

        Canary (Dark) — достаточно похожа на Blue/Green, но с одной особенностью. Новая версия сначала выкатывается для ограниченного числа пользователей. В случае отсутствия проблем мы постепенно заменяем на новую версию все приложение.
***********************************************************************************************************

***********************************************************************************************************

***********************************************************************************************************

***********************************************************************************************************

***********************************************************************************************************
